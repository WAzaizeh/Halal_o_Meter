{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "from collections import Counter\n",
    "from spacy.matcher import PhraseMatcher, Matcher\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# to import Database class from data_collection folder\n",
    "module_path = os.path.abspath(os.path.join('../..')+'/data/data_collection')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# now that the folder is in the path, ../data_collection/database.py can be imported\n",
    "from storage_managers.database import Database\n",
    "\n",
    "# initialize spacy\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw features dataframe with Spacy Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickle of dataframe with all reviews data, including Spacy Doc, and features\n",
    "data_df = pd.read_pickle('/Users/wesamazaizeh/Desktop/Projects/halal_o_meter/src/features/feature_engineering/features_draft_v2.2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make features from most common words before and after 'halal' in reviews text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_at_position_from_halal(doc_col, position=1, n=10):\n",
    "    # initialize matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    # specify match pattern\n",
    "    pattern = [{'LOWER': 'halal'}]\n",
    "    matcher.add('halal', None, pattern)\n",
    "    word_freqs = Counter()\n",
    "#     noun_freqs = Counter()\n",
    "    for doc in doc_col:\n",
    "        matches = matcher(doc)\n",
    "        words = []\n",
    "        nouns = []\n",
    "        for match_id, start, end in matches:\n",
    "            if start+position < len(doc):\n",
    "                token = doc[start+position]\n",
    "            else:\n",
    "                break\n",
    "            # all tokens that arent stop words or punctuations\n",
    "            words.append(token.text.lower() if token.is_stop != True and token.is_punct != True and token.is_space != True else '')\n",
    "#             # noun tokens that arent stop words or punctuations\n",
    "#             nouns.append(token.text.lower()) if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\" else nouns\n",
    "            # most common tokens\n",
    "        word_freq = Counter(words)\n",
    "        word_freqs = word_freqs + word_freq\n",
    "#         # most common noun tokens\n",
    "#         noun_freq = Counter(nouns)\n",
    "#         noun_freqs = noun_freqs + noun_freq\n",
    "        \n",
    "#     common_nouns = noun_freqs.most_common(n)\n",
    "    common_words = word_freqs.most_common(n)\n",
    "    return common_words #, common_nouns\n",
    "    \n",
    "common100_after_halal = common_at_position_from_halal(data_df['doc'], position=1, n=100)\n",
    "common100_before_halal = common_at_position_from_halal(data_df['doc'], position=-1, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/43]\r"
     ]
    }
   ],
   "source": [
    "# use words with more than 10 instances \n",
    "more_than_10counts = [freq[1] > 10 for freq in common100_after_halal]\n",
    "words_after = np.array(common100_after_halal)[more_than_10counts].tolist()\n",
    "words_after = [word[0] for word in words_after]\n",
    "# words_after = words_after + [''] # could be eliminated bc the \n",
    "\n",
    "more_than_10counts = [freq[1] > 10 for freq in common100_before_halal]\n",
    "words_before = np.array(common100_before_halal)[more_than_10counts].tolist()\n",
    "words_before = [word[0] for word in words_before]\n",
    "# words_before = words_before + ['']\n",
    "\n",
    "def count_matches(doc_col, words, position=1):\n",
    "    '''\n",
    "    Input: \n",
    "        - Pandas Series with Spacy Doc object for every restaurants' collection of reviews\n",
    "    Output:\n",
    "        - Pandas Dataframe with columns of counts of 'halal X' for X in arg:words. The counts are\n",
    "          per restaurant reviews\n",
    "    '''\n",
    "    # dataframe with created columns\n",
    "    if position>0:\n",
    "        df = pd.DataFrame(columns=['halal_' + word + '_count' for word in words], index=doc_col.index)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=[word + '_halal_count' for word in words], index=doc_col.index)\n",
    "    # for progress reporting\n",
    "    c=1\n",
    "    for word in words:\n",
    "        # initialize matcher\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        # specify match pattern\n",
    "        if position>0 and word:\n",
    "            pattern = [{'LOWER': 'halal'}, {'LOWER': word}]\n",
    "        elif position<0 and word:\n",
    "            pattern = [{'LOWER': word}, {'LOWER': 'halal'}]\n",
    "        else:\n",
    "            pattern = [{'LOWER': 'halal'}]\n",
    "        matcher.add('halal', None, pattern)\n",
    "        for i, doc in doc_col.iteritems():\n",
    "            matches = matcher(doc)\n",
    "            col_name = 'halal_' + word + '_count' if position>0 else word + '_halal_count'\n",
    "            df.loc[i, col_name] = len(matches)\n",
    "        print('[{}/{}]'.format(c, len(words)), end='\\r', flush=True)\n",
    "        c += 1\n",
    "    return df\n",
    "\n",
    "df_after = count_matches(data_df['doc'], words_after, position=1)\n",
    "df_before = count_matches(data_df['doc'], words_before, position=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    div_col = df.columns[np.logical_or(df.columns.str.startswith('_'), df.columns.str.contains('__'))]\n",
    "    df2 = df.drop(div_col, axis=1) \n",
    "    df2 = df2.div(df[div_col].values)\n",
    "    change_names = dict((old_name, old_name.replace('count', 'freq')) for old_name in df2.columns)\n",
    "    df2.rename(columns=change_names, inplace=True)\n",
    "    return df2\n",
    "    \n",
    "df_after = process(df_after)\n",
    "df_before = process(df_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine new features with necessary ones from version 4. Then, pickle and save\n",
    "data_df2 = pd.concat([data_df[['halal_in_name', 'halal_review_percent', 'halal']], df_after, df_before], axis=1)\n",
    "\n",
    "file_name_v5 = os.getcwd() + '/restaurant_cat_and_num_v5.pkl'\n",
    "data_df2.to_pickle(file_name_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
