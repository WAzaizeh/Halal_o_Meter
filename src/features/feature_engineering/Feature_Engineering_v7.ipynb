{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
    "from spacy.tokens import Doc\n",
    "import numpy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# to import Database class from data_collection folder\n",
    "module_path = os.path.abspath(os.path.join('../..')+'/data/data_collection')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# now that the folder is in the path, ../data_collection/database.py can be imported\n",
    "from storage_managers.database import Database\n",
    "\n",
    "# initialize spacy\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data() -> pd.DataFrame():\n",
    "    db = Database()\n",
    "    # get halal-reviews and its restaurant data\n",
    "    data_sql = '''SELECT b.platform_id, b.name as restaurant_name, r.review_text, r.username, r.rating,\n",
    "                concat(review_date,date) as review_date, r.helpful_count, b.address, b.image_url,\n",
    "                b.lat, b.lng, b.total_review_count, b.total_halal_review_count\n",
    "                FROM reviews r\n",
    "                JOIN businesses b\n",
    "                ON r.restaurant_id = b.platform_id\n",
    "                WHERE r.review_text IS NOT NULL '''\n",
    "    data_df = db.select_df(data_sql)\n",
    "    return data_df\n",
    "\n",
    "def format_columns(data_df) -> pd.DataFrame():\n",
    "    str_to_num_cols = ['rating']\n",
    "    for col in str_to_num_cols:\n",
    "        data_df[col] = data_df[col].str.extract('(\\d+)')\n",
    "        data_df[col].fillna(-1, inplace=True)\n",
    "        data_df[col] = data_df[col].astype(int)\n",
    "\n",
    "    str_to_lower = ['restaurant_name', 'review_text', 'username']\n",
    "    for col in str_to_lower:\n",
    "        data_df[col] = data_df[col].str.lower()\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def collapse_reviews(data_df, f = {}, agg_col = '') -> pd.DataFrame():\n",
    "    # combine  reviews text per restaurant\n",
    "    for col in data_df.columns[data_df.columns != agg_col]:\n",
    "        if col not in f.keys():\n",
    "            f[col] = 'first'\n",
    "    collapsed_df = data_df.groupby(agg_col, as_index=False).agg(f)\n",
    "    return collapsed_df\n",
    "    ### ignore these for now:\n",
    "    ## include date info? then have to consider classification per review and how to aggregate classifications\n",
    "    #  per restaurant?\n",
    "\n",
    "\n",
    "def clean_review_text(data_df, nlp, save_doc = True) -> pd.DataFrame():\n",
    "    # initialize NLP tools\n",
    "    punctuations = string.punctuation\n",
    "    stop_words = STOP_WORDS\n",
    "\n",
    "    # column containing review texts\n",
    "    reviews_col = data_df.columns[ data_df.columns.str.contains('text')][0]\n",
    "    if save_doc:\n",
    "        # initialize column to save Spacy doc object\n",
    "        data_df['doc'] = ''\n",
    "\n",
    "    for i, text in data_df[reviews_col].items():\n",
    "        ## clean (convert to lowercase and remove punctuations and   characters and then strip)\n",
    "        text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "        ## Tokenize (convert from string to list)\n",
    "        lst_text = text.split()\n",
    "        ## remove Stopwords\n",
    "        lst_text = [word for word in lst_text if word not in STOP_WORDS]\n",
    "        ## save Spacy doc object\n",
    "        doc = nlp(' '.join(lst_text)[:1000000])\n",
    "        if doc == '' : \n",
    "            print('index: ', i)\n",
    "        if save_doc:\n",
    "            data_df.at[i, 'doc'] = doc\n",
    "        ## Lemmatisation (convert the word into root word)\n",
    "        lem_doc = [word.lemma_ for word in doc]\n",
    "        ## back to string from list\n",
    "        data_df.loc[i, 'clean_text'] = ' '.join(lem_doc)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "def tf_idf(corpus, n=100, ngram=(1)):\n",
    "    vectorizer = TfidfVectorizer(max_features=n, ngram_range=ngram)\n",
    "    vectors = vectorizer.fit_transform(corpus)\n",
    "    names = vectorizer.get_feature_names()\n",
    "    data = vectors.todense().tolist()\n",
    "    return names, data\n",
    "\n",
    "def custom_matcher(nlp, doc_col, pattern=[], pattern_name=''):\n",
    "    # initialize matcher\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # specify match pattern\n",
    "    matcher.add(pattern_name, pattern)\n",
    "\n",
    "    res_df = pd.DataFrame(columns = [pattern_name, pattern_name+'_count'])\n",
    "    # create two columns with counts/ presence of the match respectively\n",
    "    for i, doc in doc_col.iteritems():\n",
    "        match = matcher(doc)\n",
    "        count = len(match)\n",
    "        res_df.loc[i, pattern_name+'_count'] = count\n",
    "        res_df.loc[i, pattern_name] = True if count>0 else False\n",
    "    return res_df\n",
    "\n",
    "def print_top(tfidf_dict, n=10):\n",
    "    sorted_tfidf_dict = sorted(tfidf_dict, key=lambda x: sum(tfidf_dict[x]) / len(tfidf_dict[x]), reverse=True)[:n]\n",
    "    for word in sorted_tfidf_dict:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract key words from labeled restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb gyro\n",
      "excited\n",
      "good\n",
      "halal option\n",
      "gem\n",
      "believe\n",
      "be not\n",
      "baba\n",
      "good service\n",
      "literally\n"
     ]
    }
   ],
   "source": [
    "# get review data\n",
    "test_df = fetch_data()\n",
    "\n",
    "# add basic features\n",
    "test_df['halal_in_name'] = test_df.apply(lambda row: True if 'halal' in row['restaurant_name'].lower() else False, axis=1)\n",
    "test_df['percent_halal_reviews'] = test_df['total_halal_review_count'] / test_df['total_review_count']\n",
    "\n",
    "# preprocess\n",
    "test_df = format_columns(test_df)\n",
    "agg_col = 'platform_id'\n",
    "f = {'review_text' : lambda x: ' '.join(x), \n",
    "     'rating' : 'mean',\n",
    "     'helpful_count': 'mean',}\n",
    "for col in test_df.columns:\n",
    "    if (col != agg_col) and col not in f.keys():\n",
    "        f[col] = 'first'\n",
    "test_df = collapse_reviews(test_df, f=f, agg_col=agg_col)\n",
    "\n",
    "# keep only labeled data\n",
    "target_df = pd.read_csv('/Users/wesamazaizeh/Desktop/Projects/halal_o_meter/src/features/target_feature/label_target.csv', index_col=0)\n",
    "target_df['halal'] = target_df['halal'].apply(lambda row: True if row == 'TRUE' else False)\n",
    "test_df = test_df.merge(target_df[['platform_id', 'halal']], on='platform_id')\n",
    "\n",
    "# clean up text\n",
    "test_df = clean_review_text(test_df, nlp=nlp)\n",
    "\n",
    "# extract 1000 halal keywords\n",
    "corpus = test_df['clean_text'][test_df['halal']].astype(str)\n",
    "words, scores = tf_idf(corpus, n=1000, ngram=(1,2))\n",
    "top_halal = dict( zip(words, scores))\n",
    "print('Top halal restaurant keywords by avg tfidf score:')\n",
    "print_top(top_halal, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attitude\n",
      "buy\n",
      "accommodate\n",
      "definitely\n",
      "chili\n",
      "cart pron\n",
      "beef\n",
      "definitely recommend\n",
      "black\n",
      "chicken lamb\n"
     ]
    }
   ],
   "source": [
    "# extract 1000 non-halal keywords\n",
    "non_corpus = test_df['clean_text'][~test_df['halal']].astype(str)\n",
    "non_words, non_scores = tf_idf(non_corpus, n=1000, ngram=(1,2))\n",
    "top_non_halal = dict( zip(non_words, non_scores))\n",
    "print('Top non-halal restaurant keywords by avg tfidf score:')\n",
    "print_top(top_non_halal, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much overlap is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare relative tf-idf scores rather than exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docs:\n",
    "    prupose\n",
    "    good at highly specialized data science things\n",
    "    end to end (collection, cleaning, modeling, validation, loop, productionize)\n",
    "    different models, features,\n",
    "    \n",
    "    significance\n",
    "    novelty\n",
    "    novel method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
